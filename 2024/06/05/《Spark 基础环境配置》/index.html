
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <title>《Spark 基础环境配置》 | 214800112刘津桐</title>
    <meta name="author" content="John Doe" />
    <meta name="description" content="Let us do it together" />
    <meta name="keywords" content="" />
    <meta
        name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"
    />
    <link rel="icon" href="/images/avatar.jpg" />
    <link rel="preconnect" href="https://s4.zstatic.net" />
<script src="https://s4.zstatic.net/ajax/libs/vue/3.3.7/vue.global.prod.min.js"></script>
<link rel="stylesheet" href="https://s4.zstatic.net/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
<link rel="preconnect" href="https://fonts.googleapis.cn" />
<link rel="preconnect" href="https://fonts.gstatic.cn" crossorigin />
<link
    rel="stylesheet"
    href="https://fonts.googleapis.cn/css2?family=Fira+Code:wght@400;500;600;700&family=Lexend:wght@400;500;600;700;800;900&family=Noto+Sans+SC:wght@400;500;600;700;800;900&display=swap"
/>
<script> const mixins = {}; </script>

<script src="https://polyfill.alicdn.com/v3/polyfill.min.js?features=default"></script>


<script src="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script src="https://s4.zstatic.net/ajax/libs/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
<link
    rel="stylesheet"
    href="https://s4.zstatic.net/ajax/libs/highlight.js/11.9.0/styles/github.min.css"
/>
<script src="/js/lib/highlight.js"></script>



<script src="/js/lib/preview.js"></script>









<link rel="stylesheet" href="/css/main.css" />

<meta name="generator" content="Hexo 7.2.0"></head>
<body>
    <div id="layout">
        <transition name="fade">
            <div id="loading" v-show="loading">
                <div id="loading-circle">
                    <h2>LOADING</h2>
                    <p>加载过慢请开启缓存 浏览器默认开启</p>
                    <img src="/images/loading.gif" />
                </div>
            </div>
        </transition>
        <div id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}">
    <nav id="desktop-menu">
        <a class="title" href="/">
            <span>214800112刘津桐</span>
        </a>
        
        <a href="/">
            <i class="fa-solid fa-house fa-fw"></i>
            <span>&ensp;Home</span>
        </a>
        
        <a href="/about">
            <i class="fa-solid fa-id-card fa-fw"></i>
            <span>&ensp;About</span>
        </a>
        
        <a href="/archives">
            <i class="fa-solid fa-box-archive fa-fw"></i>
            <span>&ensp;Archives</span>
        </a>
        
        <a href="/categories">
            <i class="fa-solid fa-bookmark fa-fw"></i>
            <span>&ensp;Categories</span>
        </a>
        
        <a href="/tags">
            <i class="fa-solid fa-tags fa-fw"></i>
            <span>&ensp;Tags</span>
        </a>
        
    </nav>
    <nav id="mobile-menu">
        <div class="title" @click="showMenuItems = !showMenuItems">
            <i class="fa-solid fa-bars fa-fw"></i>
            <span>&emsp;214800112刘津桐</span>
        </div>
        <transition name="slide">
            <div class="items" v-show="showMenuItems">
                
                <a href="/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-house fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Home</div>
                    </div>
                </a>
                
                <a href="/about">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-id-card fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">About</div>
                    </div>
                </a>
                
                <a href="/archives">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-box-archive fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Archives</div>
                    </div>
                </a>
                
                <a href="/categories">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-bookmark fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Categories</div>
                    </div>
                </a>
                
                <a href="/tags">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-tags fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Tags</div>
                    </div>
                </a>
                
            </div>
        </transition>
    </nav>
</div>
<transition name="fade">
    <div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div>
</transition>

        <div id="main" :class="loading ? 'into-enter-from': 'into-enter-active'">
            <div class="article">
    <div>
        <h1>《Spark 基础环境配置》</h1>
    </div>
    <div class="info">
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2024/6/5
        </span>
        
        
    </div>
    
    <div class="content" v-pre>
        <hr>
<span id="more"></span>
<p>Hadoop3.3.0–Linux编译安装</p>
<p>基础环境：Centos 7.7</p>
<p>编译环境软件安装目录<br>mkdir -p &#x2F;export&#x2F;server</p>
<p>一、Hadoop编译安装<br>&#x3D;&#x3D;可以直接使用课程提供已经编译好的安装包&#x3D;&#x3D;。<br>-安装编译相关的依赖<br>    yum install gcc gcc-c++ make autoconf automake libtool curl lzo-devel zlib-devel openssl openssl-devel ncurses-devel snappy snappy-devel bzip2 bzip2-devel lzo lzo-devel lzop libXtst zlib -y</p>
<pre><code>yum install -y doxygen cyrus-sasl* saslwrapper-devel*
</code></pre>
<p>-手动安装cmake<br>    #yum卸载已安装cmake 版本低<br>    yum erase cmake</p>
<pre><code>#解压
tar zxvf CMake-3.19.4.tar.gz

#编译安装
cd /export/server/CMake-3.19.4

./configure

make &amp;&amp; make install

#验证
[root@node4 ~]# cmake -version
cmake version 3.19.4

#如果没有正确显示版本 请断开SSH连接 重写登录
</code></pre>
<p>-手动安装snappy<br>    #卸载已经安装的</p>
<pre><code>rm -rf /usr/local/lib/libsnappy*
rm -rf /lib64/libsnappy*

#上传解压
tar zxvf snappy-1.1.3.tar.gz 

#编译安装
cd /export/server/snappy-1.1.3
./configure
make &amp;&amp; make install

#验证是否安装
[root@node4 snappy-1.1.3]# ls -lh /usr/local/lib |grep snappy
-rw-r--r-- 1 root root 511K Nov  4 17:13 libsnappy.a
-rwxr-xr-x 1 root root  955 Nov  4 17:13 libsnappy.la
lrwxrwxrwx 1 root root   18 Nov  4 17:13 libsnappy.so -&gt; libsnappy.so.1.3.0
lrwxrwxrwx 1 root root   18 Nov  4 17:13 libsnappy.so.1 -&gt; libsnappy.so.1.3.0
-rwxr-xr-x 1 root root 253K Nov  4 17:13 libsnappy.so.1.3.0
</code></pre>
<p>-安装配置JDK 1.8<br>    #解压安装包<br>    tar zxvf jdk-8u65-linux-x64.tar.gz</p>
<pre><code>#配置环境变量
vim /etc/profile

export JAVA_HOME=/export/server/jdk1.8.0_241
export PATH=$PATH:$JAVA_HOME/bin
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar

source /etc/profile

#验证是否安装成功
java -version

java version &quot;1.8.0_241&quot;
Java(TM) SE Runtime Environment (build 1.8.0_241-b07)
Java HotSpot(TM) 64-Bit Server VM (build 25.241-b07, mixed mode)
</code></pre>
<p>-安装配置maven<br>    #解压安装包<br>    tar zxvf apache-maven-3.5.4-bin.tar.gz</p>
<pre><code>#配置环境变量
vim /etc/profile

export MAVEN_HOME=/export/server/apache-maven-3.5.4
export MAVEN_OPTS=&quot;-Xms4096m -Xmx4096m&quot;
export PATH=:$MAVEN_HOME/bin:$PATH

source /etc/profile

#验证是否安装成功
[root@node4 ~]# mvn -v
Apache Maven 3.5.4

#添加maven 阿里云仓库地址 加快国内编译速度
vim /export/server/apache-maven-3.5.4/conf/settings.xml

&lt;mirrors&gt;
     &lt;mirror&gt;
           &lt;id&gt;alimaven&lt;/id&gt;
           &lt;name&gt;aliyun maven&lt;/name&gt;
           &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;
           &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;
      &lt;/mirror&gt;
&lt;/mirrors&gt;
</code></pre>
<p>-安装ProtocolBuffer 3.7.1<br>    #卸载之前版本的protobuf</p>
<pre><code>#解压
tar zxvf protobuf-3.7.1.tar.gz

#编译安装
cd /export/server/protobuf-3.7.1
./autogen.sh
./configure
make &amp;&amp; make install

#验证是否安装成功
[root@node4 protobuf-3.7.1]# protoc --version
libprotoc 3.7.1
</code></pre>
<p>-编译hadoop<br>    #上传解压源码包<br>    tar zxvf hadoop-3.3.0-src.tar.gz</p>
<pre><code>#编译
cd /root/hadoop-3.3.0-src

mvn clean package -Pdist,native -DskipTests -Dtar -Dbundle.snappy -Dsnappy.lib=/usr/local/lib

#参数说明：

Pdist,native ：把重新编译生成的hadoop动态库；
DskipTests ：跳过测试
Dtar ：最后把文件以tar打包
Dbundle.snappy ：添加snappy压缩支持【默认官网下载的是不支持的】
Dsnappy.lib=/usr/local/lib ：指snappy在编译机器上安装后的库路径
</code></pre>
<p>-编译之后的安装包路径<br>    &#x2F;root&#x2F;hadoop-3.3.0-src&#x2F;hadoop-dist&#x2F;target<br>二、Hadoop集群分布式安装<br>-基础环境<br>3台机器都需要操作<br>    # 主机名<br>    cat &#x2F;etc&#x2F;hostname</p>
<pre><code># hosts映射
vim /etc/hosts

127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

192.168.88.151 node1.itcast.cn node1
192.168.88.152 node2.itcast.cn node2
192.168.88.153 node3.itcast.cn node3

# JDK 1.8安装  上传 jdk-8u241-linux-x64.tar.gz到/export/server/目录下
cd /export/server/
tar zxvf jdk-8u241-linux-x64.tar.gz

    #配置环境变量
    vim /etc/profile

    export JAVA_HOME=/export/server/jdk1.8.0_241
    export PATH=$PATH:$JAVA_HOME/bin
    export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar

    #重新加载环境变量文件
    source /etc/profile

# 集群时间同步
ntpdate ntp5.aliyun.com

# 防火墙关闭
firewall-cmd --state	#查看防火墙状态
systemctl stop firewalld.service  #停止firewalld服务
systemctl disable firewalld.service  #开机禁用firewalld服务

# ssh免密登录（只需要配置node1至node1、node2、node3即可）

    #node1生成公钥私钥 (一路回车)
    ssh-keygen  

    #node1配置免密登录到node1 node2 node3
    ssh-copy-id node1
    ssh-copy-id node2
    ssh-copy-id node3
</code></pre>
<p>-上传Hadoop安装包到node1 &#x2F;export&#x2F;server<br>    hadoop-3.3.0-Centos7-64-with-snappy.tar.gz</p>
<pre><code>tar zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz
</code></pre>
<p>-修改配置文件(配置文件路径 hadoop-3.3.0&#x2F;etc&#x2F;hadoop)<br>hadoop-env.sh<br>    #文件最后添加<br>    export JAVA_HOME&#x3D;&#x2F;export&#x2F;server&#x2F;jdk1.8.0_241</p>
<pre><code>export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
</code></pre>
<p>core-site.xml<br>    <!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --><br>    <property><br>        <name>fs.defaultFS</name><br>        <value>hdfs:&#x2F;&#x2F;node1:8020</value><br>    </property></p>
<pre><code>&lt;!-- 设置Hadoop本地保存数据路径 --&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
    &lt;value&gt;/export/data/hadoop-3.3.0&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 设置HDFS web UI用户身份 --&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
    &lt;value&gt;root&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 整合hive 用户代理设置 --&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt;
    &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
    &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt;
    &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 文件系统垃圾桶保存时间 --&gt;
&lt;property&gt;
    &lt;name&gt;fs.trash.interval&lt;/name&gt;
    &lt;value&gt;1440&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>hdfs-site.xml<br>    <!-- 设置SNN进程运行机器位置信息 --><br>    <property><br>        <name>dfs.namenode.secondary.http-address</name><br>        <value>node2:9868</value><br>    </property><br>mapred-site.xml<br>    <!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --><br>    <property><br>      <name>mapreduce.framework.name</name><br>      <value>yarn</value><br>    </property></p>
<pre><code>&lt;!-- MR程序历史服务地址 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
  &lt;value&gt;node1:10020&lt;/value&gt;
&lt;/property&gt;

&lt;!-- MR程序历史服务器web端地址 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
  &lt;value&gt;node1:19888&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;
  &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;mapreduce.map.env&lt;/name&gt;
  &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;
  &lt;value&gt;HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>yarn-site.xml<br>    <!-- 设置YARN集群主角色运行机器位置 --><br>    <property><br>        <name>yarn.resourcemanager.hostname</name><br>        <value>node1</value><br>    </property></p>
<pre><code>&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 是否将对容器实施物理内存限制 --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 开启日志聚集 --&gt;
&lt;property&gt;
  &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 设置yarn历史服务器地址 --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.log.server.url&lt;/name&gt;
    &lt;value&gt;http://node1:19888/jobhistory/logs&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 历史日志保存的时间 7天 --&gt;
&lt;property&gt;
  &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
  &lt;value&gt;604800&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>workers<br>    node1.itcast.cn<br>    node2.itcast.cn<br>    node3.itcast.cn<br>-分发同步hadoop安装包<br>    cd &#x2F;export&#x2F;server</p>
<pre><code>scp -r hadoop-3.3.0 root@node2:$PWD
scp -r hadoop-3.3.0 root@node3:$PWD
</code></pre>
<p>-将hadoop添加到环境变量（3台机器）<br>    vim &#x2F;etc&#x2F;profile</p>
<pre><code>export HADOOP_HOME=/export/server/hadoop-3.3.0
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

source /etc/profile

#别忘了scp给其他两台机器哦
</code></pre>
<p>-Hadoop集群启动<br>（&#x3D;&#x3D;首次启动&#x3D;&#x3D;）格式化namenode</p>
<pre><code>hdfs namenode -format
</code></pre>
<p>脚本一键启动<br>    [root@node1 ~]# start-dfs.sh<br>    Starting namenodes on [node1]<br>    Last login: Thu Nov  5 10:44:10 CST 2020 on pts&#x2F;0<br>    Starting datanodes<br>    Last login: Thu Nov  5 10:45:02 CST 2020 on pts&#x2F;0<br>    Starting secondary namenodes [node2]<br>    Last login: Thu Nov  5 10:45:04 CST 2020 on pts&#x2F;0</p>
<pre><code>[root@node1 ~]# start-yarn.sh 
Starting resourcemanager
Last login: Thu Nov  5 10:45:08 CST 2020 on pts/0
Starting nodemanagers
Last login: Thu Nov  5 10:45:44 CST 2020 on pts/0
</code></pre>
<ul>
<li><p>Web  UI页面</p>
<ul>
<li>HDFS集群：<a target="_blank" rel="noopener" href="http://node1:9870/">http://node1:9870/</a></li>
<li>YARN集群：<a target="_blank" rel="noopener" href="http://node1:8088/">http://node1:8088/</a></li>
</ul>
</li>
<li><p>错误1:运行hadoop3官方自带mr示例出错。<br>错误信息<br>  Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster</p>
<p>  Please check whether your etc&#x2F;hadoop&#x2F;mapred-site.xml contains the below configuration:</p>
  <property>
    <name>yarn.app.mapreduce.am.env</name>
    <value>HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}</value>
  </property>
  <property>
    <name>mapreduce.map.env</name>
    <value>HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}</value>
  </property>
  <property>
    <name>mapreduce.reduce.env</name>
    <value>HADOOP_MAPRED_HOME=${full path of your hadoop distribution directory}</value>
  </property></li>
</ul>
<p>解决  mapred-site.xml,增加以下配置<br>    <property><br>      <name>yarn.app.mapreduce.am.env</name><br>      <value>HADOOP_MAPRED_HOME&#x3D;${HADOOP_HOME}</value><br>    </property><br>    <property><br>      <name>mapreduce.map.env</name><br>      <value>HADOOP_MAPRED_HOME&#x3D;${HADOOP_HOME}</value><br>    </property><br>    <property><br>      <name>mapreduce.reduce.env</name><br>      <value>HADOOP_MAPRED_HOME&#x3D;${HADOOP_HOME}</value><br>    </property></p>
<p><strong>第一步</strong> 准备工作</p>
<pre><code>安装前需要安装好jdk

检测集群时间是否同步
检测防火墙是否关闭
检测主机 ip映射有没有配置
</code></pre>
<p><strong>第二步</strong> 解压</p>
<p>在node1主机上，解压zookeeper的压缩包到&#x2F;export&#x2F;server路径下去，然后准备进行安装</p>
<pre><code>cd /export/software
tar -zxvf zookeeper.tar.gz -C /export/server/
cd /export/server/
ln -s zookeeper/ zookeeper
</code></pre>
<p><strong>第三步</strong> 环境变量</p>
<pre><code>##修改环境变量（注意：3台zookeeper都需要修改）

vi /etc/profile
export ZOOKEEPER_HOME=/export/server/zookeeper
export PATH=$PATH:$ZOOKEEPER_HOME/bin
source /etc/profile
</code></pre>
<p><strong>第四步</strong> 配置文件</p>
<pre><code>##修改Zookeeper配置文件
cd /export/server/zookeeper/conf/
cp zoo_sample.cfg zoo.cfg
mkdir -p /export/data/zookeeper/zkdatas/
vim zoo.cfg
</code></pre>
<p>修改以下内容</p>
<pre><code>#Zookeeper的数据存放目录
dataDir = /export/data/zookeeper/zkdatas/
# 保留多少个快照
autopurge.snapRetainCount = 3
# 日志多少小时清理一次
autopurge.purgeInterval = 1
# 集群中服务器地址
server.1 = node1:2888:3888
server.2 = node2:2888:3888
server.3 = node3:2888:3888
</code></pre>
<p>**第五步 **添加myid配置</p>
<p>在node1主机的这个路径下创建一个文件，文件名为myid ,文件内容为1</p>
<pre><code>echo 1 &gt; /export/data/zookeeper/zkdatas/myid 
</code></pre>
<p>**第六步 ** 安装包分发并修改myid的值</p>
<p>在node1主机上，将安装包分发到其他机器</p>
<p>第一台机器上面执行以下两个命令</p>
<pre><code>cd /export/server/

scp -r /export/server/zookeeper-3.4.6/ root@node2:/export/server/

scp -r /export/server/zookeeper-3.4.6/ root@node3:/export/server/
</code></pre>
<p>第二台机器上建立软连接, 并修改myid的值为2</p>
<pre><code>cd /export/server/

ln -s zookeeper-3.4.6/ zookeeper

echo 2 &gt; /export/data/zookeeper/zkdatas/myid
</code></pre>
<p>第三台机器上建立软连接, 并修改myid的值为3</p>
<pre><code>cd /export/server/

ln -s zookeeper-3.4.6/ zookeeper

echo 3 &gt; /export/data/zookeeper/zkdatas/myid
</code></pre>
<p>**第七步 ** 三台机器启动zookeeper服务</p>
<p>三台机器分别启动zookeeper服务</p>
<p>这个命令三台机器都要执行</p>
<pre><code>/export/server/zookeeper/bin/zkServer.sh start
</code></pre>
<p>三台主机分别查看启动状态</p>
<pre><code>/export/server/zookeeper/bin/zkServer.sh status
</code></pre>
<p>##启动（每台机器）<br>zkServer.sh start<br>或者编写一个脚本来批量启动所有机器：</p>
<p>方法1：</p>
<pre><code>for host in &quot;node1 node2 node3&quot;
do
   ssh $host &quot;source/etc/profile;/export/server/zookeeper/bin/zkServer.sh start&quot;
done
</code></pre>
<p>方法2：</p>
<p>1.创建&#x2F;export&#x2F;shell目录</p>
<pre><code>mkdir /export/shell
</code></pre>
<p>2.编辑创建zk.sh</p>
<pre><code>vim zkall.sh
</code></pre>
<p>3.写shell脚本</p>
<pre><code>#!/bin/bash

case $1 in
&quot;start&quot;)&#123;
    for i in node1 node2 node3
    do
        echo ---------- zookeeper $i 启动 ------------
        ssh $i &quot;/export/server/zookeeper/bin/zkServer.sh start&quot;
    done
&#125;;;
&quot;stop&quot;)&#123;
    for i in node1 node2 node3
    do
        echo ---------- zookeeper $i 停止 ------------ 
        ssh $i &quot;/export/server/zookeeper/bin/zkServer.sh stop&quot;
    done
&#125;;;
&quot;status&quot;)&#123;
    for i in node1 node2 node3
    do
        echo ---------- zookeeper $i 状态 ------------ 
        ssh $i &quot;/export/server/zookeeper/bin/zkServer.sh status&quot;
    done
&#125;;;
esac
</code></pre>
<p>4.配置zk脚本环境变量</p>
<pre><code>#SHELL_HOME
export SHELL_HOME=/export/shell/
export PATH=$PATH:$SHELL_HOME
</code></pre>
<p>6.让环境变量生效</p>
<pre><code>source /etc/profile
</code></pre>
<p>7.启动测试</p>
<pre><code>chmod 777 /export/shell/zkall.sh
zkall.sh start
</code></pre>
<p>方法3：</p>
<pre><code>#!/bin/bash
if [ $# -eq 0 ] #  $#参数的个数
then
    echo &quot;please input param:start stop status&quot;
else
    if [ $1 = start  ]
    then
        for i in &#123;1..3&#125;
        do
            echo &quot;$&#123;1&#125;ing node$&#123;i&#125;&quot;
            ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh start&quot;
        done
    fi

    if [ $1 = stop ]
    then
        for i in &#123;1..3&#125;
        do
            echo &quot;$&#123;1&#125;ping node$&#123;i&#125;&quot;
            ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh stop&quot;
        done
    fi

    if [ $1 = status ]
    then
        for i in &#123;1..3&#125;
        do
            echo &quot;node$&#123;i&#125; status:&quot;
            ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/zookeeper/bin/zkServer.sh status&quot;
        done
    fi

fi

#!/bin/bash
if [ $# -eq 0 ]
then
    echo &quot;please input param:start stop&quot;
else
    if [ $1 = start  ]
        then
            for i in &#123;1..3&#125;
            do
                echo &quot;$&#123;1&#125;ing node$&#123;i&#125;&quot;
                ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/kafka/bin/kafka-server-start.sh -daemon /export/server/kafka/config/server.properties&quot;
            done
    fi

    if [ $1 = stop ]
        then
            for i in &#123;1..3&#125;
            do
                echo &quot;$&#123;1&#125;ing node$&#123;i&#125;&quot;
                ssh node$&#123;i&#125; &quot;source 		/etc/profile;/export/server/kafka/bin/kafka-server-stop.sh&quot;
            done
    fi

    if [ $1 = status ]
        then
            for i in &#123;1..3&#125;
            do
                echo &quot;node$&#123;i&#125; status:&quot;
                ssh node$&#123;i&#125; &quot;source /etc/profile;/export/server/kafka/bin/kafka-server-status.sh&quot;
            done
    fi
fi
</code></pre>
<p>配置文件中参数说明:</p>
<pre><code>tickTime这个时间是作为zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔,也就是说每个tickTime时间就会发送一个心跳。

initLimit这个配置项是用来配置zookeeper接受客户端（这里所说的客户端不是用户连接zookeeper服务器的客户端,而是zookeeper服务器集群中连接到leader的follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。

当已经超过10个心跳的时间（也就是tickTime）长度后 zookeeper 服务器还没有收到客户端的返回信息,那么表明这个客户端连接失败。总的时间长度就是 10*2000=20秒。

syncLimit这个配置项标识leader与follower之间发送消息,请求和应答时间长度,最长不能超过多少个tickTime的时间长度,总的时间长度就是5*2000=10秒。

dataDir顾名思义就是zookeeper保存数据的目录,默认情况下zookeeper将写数据的日志文件也保存在这个目录里；

clientPort这个端口就是客户端连接Zookeeper服务器的端口,Zookeeper会监听这个端口接受客户端的访问请求；

server.A=B:C:D中的A是一个数字,表示这个是第几号服务器,B是这个服务器的IP地址，C第一个端口用来集群成员的信息交换,表示这个服务器与集群中的leader服务器交换信息的端口，D是在leader挂掉时专门用来进行选举leader所用的端口。
</code></pre>
<hr>
<pre><code>export JAVA_HOME=/export/server/jdk
export PATH=$PATH:$JAVA_HOME/bin
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
</code></pre>

    </div>
    
    
    
    
    
    
    
</div>

            <footer id="footer">
    <div id="footer-wrap">
        <div>
            &copy;
            2022 - 2024 214800112刘津桐
            <span id="footer-icon">
                <i class="fa-solid fa-font-awesome fa-fw"></i>
            </span>
            &commat;John Doe
        </div>
        <div>
            Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp;
            <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a>
        </div>
        
    </div>
</footer>

        </div>
        
        <transition name="fade">
            <div id="preview" ref="preview" v-show="previewShow">
                <img id="preview-content" ref="previewContent" />
            </div>
        </transition>
        
    </div>
    <script src="/js/main.js"></script>
    
    




    
</body>
</html>
